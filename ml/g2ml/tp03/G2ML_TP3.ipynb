{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> TP 3 : Apprentissage d'un mélange - Algorithme EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline \n",
    "\n",
    "from mnist import load_mnist\n",
    "import numpy as np\n",
    "import visualize as vz\n",
    "import random as rd\n",
    "\n",
    "train_data, train_labels = load_mnist(dataset='training', path='./')\n",
    "test_data, test_labels = load_mnist(dataset='testing', path='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation de `train_data` et `test_data` en vecteur colonne pour chaque exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = np.reshape(train_data, (60000, 28 * 28)).T\n",
    "test_data  = np.reshape(test_data,  (10000, 28 * 28)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarisation des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAACbCAYAAABVqOFYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQAgNGSDEPyp7sxY00FSvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ccc445a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binarize = lambda x : x < 128 / 255\n",
    "vfunc = np.vectorize(binarize)\n",
    "train_data = vfunc(train_data)\n",
    "test_data = vfunc(test_data)\n",
    "\n",
    "vz.plotGroupImages(train_data[:, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Théorie\n",
    "\n",
    "A partir de ce qui a été vu en cours, déduire les étapes de l'algorithme EM pour l'apprentissage des paramètres d'un mélange de loi de Bernoulli. Donner les formules de mise à jour des différents paramètres du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "L'algorithme EM fonctionne suivant deux étapes :\n",
    "* L'étape appelée \"expectation\", qui consiste à calculer tous les poids de tous les points pour toutes les composantes.\n",
    "* L'étape appelée \"maximization\", qui vise à recalculer les moyennes pour chaque composante, en modifiant les poids de chaque composante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pose N correspondant aux nombres d'éléments dans le dataset {$X_1, \\ldots, X_n$}, K correspondant aux nombres de composantes souhaitées,\n",
    "$w_i$ le poid associé à la i-ème composante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 1 : Initialisation des paramètres**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialisation des moyennes de chaque composante.\n",
    "* Initialisation des poids, tels que $\\sum_{i=1}^{K}{w_i} = \\sum_{i=1}^K{P(i)} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 2 : Expectation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nous savons que la vraisemblance $P(X_i | \\mu_k) = \\mu_k^{X_i} (1 − \\mu_k)^{N − X_i}$ en utilisant une distribution de Bernoulli.\n",
    "* On calcule l'a posteriori : $P(k|X_i) = \\frac{w_k P(X_i|\\mu_k)}{\\sum_{j=1}^{K}{w_j P(X_j|\\mu_k)}} = \\frac{w_k (\\mu_k^{X_i} (1 − \\mu_k)^{N − X_i})}{\\sum_{j=1}^{K}{w_j (\\mu_k^{X_j}(1 − \\mu_k)^{N − X_j})}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etape 3 : Maximization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On calcule de nouveaux poids : $P(k) = w_k = \\frac{\\sum_{i=1}^{N}{P(k|X_i)}}{N}$\n",
    "* On calcule les nouvelles moyennes : $\\mu_k = \\frac{\\sum_{i=1}^{N}{P(k|X_i)X_i}}{\\sum_{i=1}^{N}{P(k|X_i)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Implémentation\n",
    "\n",
    "On vous demandera de tester différentes valeurs pour le nombre de composantes du mélange ainsi que différentes initialisations du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Implémenter cet algorithme et faire l'apprentissage sur les données binaires TRAINB obtenues précedemment. Attention à la manipulation des valeurs de probabilités (entre 0 et 1) qui deviennent rapidement nulles à cause de la précision des chiffres flottants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EmBernoulli:\n",
    "    def __init__(self, data, nbComponents):\n",
    "        self.data = data\n",
    "        self.nbComponents = nbComponents\n",
    "\n",
    "    def _init_center(self):\n",
    "        self.center = np.zeros((self.data.shape[0], self.nbComponents))\n",
    "        minimages = self.data.shape[1] // 4\n",
    "        for i in range(self.nbComponents):\n",
    "            mini = 0\n",
    "            maxi = rd.randint(minimages, self.data.shape[1])\n",
    "            self.center[:, i] = np.mean(self.data[:, mini:maxi], axis=1)\n",
    "\n",
    "    def computeEM(self):\n",
    "        delta = 1e-2\n",
    "        # P(k)\n",
    "        self.W = np.repeat(1 / self.nbComponents, self.nbComponents)\n",
    "        self._init_center()\n",
    "        \n",
    "        while True:\n",
    "            self._expectationStep()\n",
    "            newW, newCenter = self._maximizationStep()\n",
    "            diff = np.sum(np.abs(newW - self.W))\n",
    "            if diff < delta:\n",
    "                return newW, newCenter\n",
    "            self.W = newW\n",
    "            self.center = newCenter\n",
    "\n",
    "    def _bernoulli(self, x, center):\n",
    "        # proba is P(X1, ..., Xn)\n",
    "        proba = np.zeros(x.shape)\n",
    "        # Retrieve indices of black and white pixels.\n",
    "        indices = [np.array(np.where(x == i)) for i in range(2)]\n",
    "        proba[indices[0]] = 1 - center[indices[0]]\n",
    "        proba[indices[1]] = center[indices[1]]\n",
    "        prod = np.prod(proba)\n",
    "\n",
    "        # This lines allow to fix NaN problems,\n",
    "        # by replacing them by smallest epsilon\n",
    "        if np.isnan(prod) or prod <= 0:\n",
    "            return np.finfo(prod.dtype).tiny\n",
    "        return prod\n",
    "\n",
    "    def _expectationStep(self):\n",
    "        N = self.data.shape[1]\n",
    "        K = self.nbComponents\n",
    "        self.tabl = np.zeros((N, K))\n",
    "\n",
    "        for n in range(N):\n",
    "            for k in range(K):\n",
    "                # Probability for the image to be from K class.\n",
    "                self.tabl[n, k] = np.log(self._bernoulli(self.data[:, n], self.center[:, k])) + np.log(self.W[k])\n",
    "                \n",
    "            maxValue = np.amax(self.tabl[n, :])\n",
    "            normTabl = self.tabl[n, :] - maxValue\n",
    "            tablSum = np.sum(np.exp(normTabl))\n",
    "            self.tabl[n, :] = np.exp(normTabl - np.log(tablSum))\n",
    "\n",
    "    def _maximizationStep(self):\n",
    "        N = self.tabl.shape[0]\n",
    "        tsum = np.sum(self.tabl, axis=0)\n",
    "        W =  tsum / N\n",
    "        center = np.dot(self.data, self.tabl) / tsum\n",
    "        return W, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_classes = [train_data[:, np.where(train_labels == i)[0]]\n",
    "                        for i in range(10)]\n",
    "emb = EmBernoulli(train_classes[3], 4)\n",
    "W, center = emb.computeEM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Afficher les moyennes des différentes distributions de Bernoulli ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABeCAYAAAAUjW5fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTvgPtKIx10c12+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c96eb3ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vz.plotGroupImages(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** En utilisant uniquement 10 composantes, est-il possible d'avoir un centre par classe ? Justifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Tester un classifieur bayésien en utilisant un mélange pour chaque classe ? Quel est le taux de reconnaissance obtenu (tester 1, 2, 4, et 8 composantes par classe) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : Comparaison avec un GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Comparer les résultats obtenus avec le cas d'un mélange de gaussiennes sur les données brutes TRAIN et TEST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On a $N(X; \\mu, \\Theta) = \\frac{1}{\\sqrt{(2\\pi)^D|\\Theta|}} exp(-0.5(X - \\mu)^T\\Theta^{-1}(X - \\mu))$\n",
    "* La vraisemblance : $P(k|X) = \\frac{w_k N(X;\\mu_k,\\Theta_k)}{\\sum_{j=1}^{N}{w_j N(X,\\mu_j,\\Theta_j)}}$\n",
    "* $P(k) = \\frac{\\sum_{i=1}^{N}{P(k|X_i)}}{N}$\n",
    "* $\\mu_k = \\frac{\\sum_{i=1}^{N}{P(k|X_i)X_i}}{\\sum_{i=1}^{N}{P(k|X_i)}}$\n",
    "* $\\Theta_k = \\frac{\\sum_{i=1}^{N}{P(k|X_i)(X_i - \\mu_k)^2}}{\\sum_{i=1}^{N}{P(k|X_i)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Envisager le cas de gaussienne avec des matrices de covariance diagonale, ensuite tester la version avec matrices de covariance complètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmGaussian:\n",
    "    def _init_center_cov(self):\n",
    "        self.center = np.zeros((self.data.shape[0], self.nbComponents))\n",
    "        #cov = [np.zeros((data.shape[0], data.shape[0])) for i in\n",
    "        #        range(nbComponents)]\n",
    "        self.cov = [np.identity(self.data.shape[0]) for i in\n",
    "                    range(self.nbComponents)]\n",
    "        minimages = self.data.shape[1] // 4\n",
    "\n",
    "        for i in range(self.nbComponents):\n",
    "            maxi = rd.randint(minimages, self.data.shape[1])\n",
    "            self.center[:, i] = np.mean(self.data[:, minimages:maxi], axis=1)\n",
    "            #cov[i] = np.cov(data[:, minimages:maxi])\n",
    "\n",
    "\n",
    "    def __init__(self, data, nbComponents):\n",
    "        self.data = data\n",
    "        self.nbComponents = nbComponents\n",
    "        self.delta = 1e-2\n",
    "\n",
    "    def computeEM(self):\n",
    "        # P(k)\n",
    "        self.W = np.repeat(1 / self.nbComponents, self.nbComponents)\n",
    "        self._init_center_cov()\n",
    "\n",
    "        while True:\n",
    "            self._expectationStep()\n",
    "            oldW = self.W\n",
    "            self._maximizationStep(tabl, center, data)\n",
    "            if np.sum(np.abs(W - oldW)) < self.delta:\n",
    "                return self.W, self.center, self.cov\n",
    "\n",
    "    def _gaussian(self, x, k):\n",
    "        # Here, we have to use the logarithm\n",
    "        # in order to store the value in a double\n",
    "        D = x.shape[0]\n",
    "        xcentered = x - self.center[:, k]\n",
    "        covdet = np.linalg.det(self.cov[k])\n",
    "        covinv = np.linalg.pinv(self.cov[k])\n",
    "        #piN = (2 * np.pi) ** D\n",
    "        #denom = np.sqrt(piN * covdet)\n",
    "        a = -0.5 * xcentered.T.dot(covinv).dot(xcentered)\n",
    "        return -0.5 * (D * np.log(2 * np.pi) * np.log(covdet)) + a\n",
    "        #return np.exp(-0.5 * xcentered.T.dot(covinv.dot(xcentered))) / denom\n",
    "\n",
    "    def _expectationStep(self):\n",
    "        N = self.data.shape[1] # Number of data.\n",
    "        D = self.data.shape[0] # Number of pixels.\n",
    "        K = self.W.shape[0] # Number of classes.\n",
    "        self.tabl = np.zeros((N, K))\n",
    "        # Likelihood\n",
    "        for n in range(N):\n",
    "            for k in range(K):\n",
    "                # print(\"EXPECTATION n =\", n, \"k =\", k)\n",
    "                # Probability for the image to be from K class.\n",
    "                self.tabl[n, k] = self._gaussian(self.data[:, n], k) * self.W[k]\n",
    "            tsum = np.sum(self.tabl[n, :])\n",
    "            self.tabl[n, :] = self.tabl[n, :] / tsum\n",
    "\n",
    "    def _maximizationStep(self):\n",
    "        print(\"MAXIMIZATION\")\n",
    "        N = self.tabl.shape[0] # Number of data.\n",
    "        K = self.tabl.shape[1] # Number of classes.\n",
    "        D = self.data.shape[0] # Number of pixels.\n",
    "        tsum = np.sum(self.tabl, axis=0)\n",
    "        oldcenter = W\n",
    "        # Weights\n",
    "        self.W =  tsum / N\n",
    "        # Means\n",
    "        self.center = np.dot(self.data, self.tabl) / tsum\n",
    "        # Covariances\n",
    "        xcentered = np.power(self.data - oldcenter, 2)\n",
    "        self.cov = np.dot(xcentered, self.tabl) / tsum\n",
    "        print(self.cov.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#emg = EmGaussian(test_data, 10)\n",
    "#W, center, cov = emg.computeEM()\n",
    "#vz.plotGroupImages(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Attention à la dégénérescence de l'algorithme EM (matrice de covariance non inversible). Il faut voir comment gérer ce problème ainsi que l'initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** Proposer la meilleure solution pour avoir le plus haut taux de reconnaissance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
